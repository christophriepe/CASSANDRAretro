{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('../5_general_data/5_5_final.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the targets for analysis.\n",
    "targets: list[str] = ['target_90_day_mortality', 'target_30_day_mortality']\n",
    "\n",
    "# Define the systems for analysis.\n",
    "systems: dict[int] = {'all': -1, 'esophagus': 0, 'stomach': 1, 'intestine': 2, 'liver': 3, 'pancreas': 4}\n",
    "\n",
    "# Define the number of iterations of the k-fold cross-validation.\n",
    "k: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'logistic_sgd': SGDClassifier(loss='log_loss', class_weight='balanced', n_jobs=-1, random_state=0),\n",
    "    'logistic_regression': LogisticRegression(class_weight='balanced', n_jobs=-1),\n",
    "    'modified_huber_sgd': SGDClassifier(loss=\"modified_huber\", class_weight=\"balanced\", n_jobs=-1, random_state=0),\n",
    "    'squared_hinge_sgd': SGDClassifier(loss=\"squared_hinge\", class_weight=\"balanced\", n_jobs=-1, random_state=0),\n",
    "    'linear_sgd': SGDClassifier(class_weight=\"balanced\", n_jobs=-1, random_state=0),\n",
    "    'naive_bayes': GaussianNB(),\n",
    "    'linear_svc': LinearSVC(class_weight=\"balanced\", random_state=0),\n",
    "    'knn_2': KNeighborsClassifier(n_neighbors=2, n_jobs=-1),\n",
    "    'knn_3': KNeighborsClassifier(n_neighbors=3, n_jobs=-1),\n",
    "    'knn_4': KNeighborsClassifier(n_neighbors=4, n_jobs=-1),\n",
    "    'knn_5': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    'knn_6': KNeighborsClassifier(n_neighbors=6, n_jobs=-1),\n",
    "    'knn_7': KNeighborsClassifier(n_neighbors=7, n_jobs=-1),\n",
    "    'knn_8': KNeighborsClassifier(n_neighbors=8, n_jobs=-1),\n",
    "    'knn_9': KNeighborsClassifier(n_neighbors=9, n_jobs=-1),\n",
    "    'knn_10': KNeighborsClassifier(n_neighbors=10, n_jobs=-1),\n",
    "    'quadratic_discriminant': QuadraticDiscriminantAnalysis(),\n",
    "    'ada_boost': AdaBoostClassifier(random_state=0),\n",
    "    'linear_discriminant': LinearDiscriminantAnalysis(),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0),\n",
    "    'random_forest': RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1, random_state=0),\n",
    "    'rbf_svc': SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=0),\n",
    "    'poly_svc_cubic': SVC(kernel=\"poly\", degree=3, class_weight=\"balanced\", random_state=0),  # hangs\n",
    "    'poly_svc_quadratic': SVC(kernel=\"poly\", degree=2, class_weight=\"balanced\", random_state=0),\n",
    "    'hinge_sgd': SGDClassifier(random_state=0, class_weight=\"balanced\", n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, model):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the Model.\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    metrics = {\n",
    "        'roc_auc': roc_auc.item(),\n",
    "        'accuracy': accuracy.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item(),\n",
    "        'f1': f1.item(),\n",
    "        'specificity': specificity.item(),\n",
    "        'sensitivity': sensitivity.item(),\n",
    "        'true_negative': tn.item(),\n",
    "        'false_positive': fp.item(),\n",
    "        'false_negative': fn.item(),\n",
    "        'true_positive': tp.item()\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_k_fold(set: pd.DataFrame, model, model_name) -> pd.DataFrame:\n",
    "    # Implement a k-fold cross validation.\n",
    "    kf = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)\n",
    "\n",
    "    # Split data into features and target\n",
    "    X = set.copy().drop('target', axis=1)\n",
    "    y = set['target']\n",
    "\n",
    "    # Set up k-fold cross validation\n",
    "    metrics = []\n",
    "    for train_index , test_index in kf.split(X, y):\n",
    "        # split data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # normalize X\n",
    "        # fit scaler on training data\n",
    "        norm = MinMaxScaler().fit(X_train)\n",
    "        # transform training data\n",
    "        X_train = norm.transform(X_train)\n",
    "        # transform testing data\n",
    "        X_test = norm.transform(X_test)\n",
    "\n",
    "        # evaluate the model\n",
    "        metrics.append(evaluate(X_train, y_train, X_test, y_test, model))\n",
    "\n",
    "    # convert the metrics dictionary into a Series.\n",
    "    mean_metrics = pd.DataFrame.from_records(metrics).mean().to_frame().T\n",
    "    mean_metrics.insert(loc = 0, column = 'estimator', value = model_name)\n",
    "    return mean_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataframe for storing the results.\n",
    "results: list[pd.Series] = []\n",
    "\n",
    "# Loop through each target.\n",
    "for target in tqdm(targets, desc='Targets'):\n",
    "    # Create local copy of the data.\n",
    "    target_data = data.copy()\n",
    "\n",
    "    # Rename target column and remove all other target columns.\n",
    "    target_data.rename(columns={target: 'target'}, inplace=True)\n",
    "    target_data.drop([col for col in target_data.columns if 'target_' in col], axis=1, inplace=True)\n",
    "\n",
    "    # Fill NaN values with -1.\n",
    "    target_data.fillna(-1, inplace=True)\n",
    "\n",
    "    # Loop through each system.\n",
    "    for system_name, system in tqdm(systems.items(), desc='Systems'):\n",
    "        # Create a local copy of target data.\n",
    "        system_data = target_data.copy()\n",
    "\n",
    "        # Check if the given system is not 'all'.\n",
    "        if system != -1:\n",
    "            # Filter the data by the given system.\n",
    "            system_data = system_data[system_data['meta_system'] == system]\n",
    "        \n",
    "        # Remove all meta columns.\n",
    "        system_data.drop([col for col in system_data.columns if 'meta_' in col], axis=1, inplace=True)\n",
    "\n",
    "        # Skip if positive target class is smaller than the given k.\n",
    "        if sum(system_data['target']) < k: continue\n",
    "\n",
    "        # Loop through all estimators.\n",
    "        for estimator_name, estimator in estimators.items():\n",
    "            # Evaluate the estimator, add the relevant characteristics and append the result to the results list.\n",
    "            result = evaluate_k_fold(system_data, estimator, estimator_name)\n",
    "            result.insert(loc = 0, column = 'system', value = system_name)\n",
    "            result.insert(loc = 0, column = 'target', value = target)\n",
    "            results.append(result)\n",
    "\n",
    "# Concat the results, save them to a csv file and display them.\n",
    "results = pd.concat(results)\n",
    "results.to_csv('11_2_results.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list for storing the best results\n",
    "best_results: list[pd.DataFrame] = []\n",
    "\n",
    "for target, target_data in results.groupby('target'):\n",
    "    for system, system_data in target_data.groupby('system'):\n",
    "        # Get the row with the best roc_auc score and append the result to the results list.\n",
    "        best_result = system_data.nlargest(1, 'roc_auc')\n",
    "        best_results.append(best_result)\n",
    "\n",
    "# Concat the best_results, save them to a csv file and display them.\n",
    "best_results = pd.concat(best_results)\n",
    "best_results.to_csv('11_3_best_results.csv')\n",
    "best_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
